# ðŸš€ LatSpace AI

> AI-Powered Excel Parsing + Parameter Onboarding Platform  
> Built with FastAPI â€¢ Streamlit â€¢ Gemini 1.5 Flash  
> Fully containerized & deployed on Railway

---

## ðŸŒ Live Deployment

| Service | Link |
|----------|------|
| ðŸ“˜ Backend API Docs | https://latspace-ai-production.up.railway.app/docs |
| ðŸ“Š Track A â€” Excel Parser | https://amused-happiness-production.up.railway.app |
| ðŸ§­ Track B â€” Onboarding Wizard | https://diligent-luck-production.up.railway.app |

---

# ðŸ§  Project Overview

LatSpace AI is a hybrid AI + deterministic system designed to intelligently onboard structured data from messy sources.

It demonstrates how to use LLMs responsibly in production systems by:

- Using AI only where semantic reasoning is required
- Keeping value parsing deterministic
- Strictly validating all outputs
- Minimizing LLM cost with optimized call design

This is not just an LLM demo â€” itâ€™s a system-level engineering solution.

---

# ðŸŽ¯ Track A â€” Excel Parser

### ðŸ” What It Does

- Upload messy multi-sheet Excel files
- Uses Gemini to map fuzzy headers â†’ canonical parameter names
- Parses values deterministically in Python
- Validates structure using Pydantic
- Detects duplicates across sheets
- Returns structured JSON output

### ðŸ— Design Principles

- âœ… **One LLM call per sheet** (NOT per column or per cell)
- âœ… LLM only for semantic header mapping
- âœ… Deterministic parsing for all values
- âœ… Strict schema validation
- âœ… Multi-sheet support

This keeps cost low while maintaining intelligent mapping capability.

---

# ðŸ§­ Track B â€” Onboarding Wizard

### ðŸ” What It Does

- Guided multi-step onboarding flow
- Parameter registry selection
- Formula validation
- Context-aware AI suggestions via Gemini
- Structured submission payload

### âš™ï¸ Technical Highlights

- FastAPI validation layer
- Strongly typed Pydantic request/response models
- Controlled temperature strategy
- Hybrid deterministic + AI-driven logic

---

# ðŸ¤– LLM Configuration

**Model:** Google Gemini 1.5 Flash  

Why this model?

- Fast
- Free-tier friendly
- Strong JSON instruction following
- Reliable structured outputs

### ðŸŽ› Temperature Strategy

- `0.1` â†’ Deterministic header mapping (Track A)
- `0.3` â†’ Suggestion generation (Track B)

---

# ðŸ— System Architecture

```
latspace-ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ agents/         # Gemini LLM agents
â”‚   â”‚   â”œâ”€â”€ models/         # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ routers/        # FastAPI endpoints
â”‚   â”‚   â””â”€â”€ utils/          # Registry loader, value parser
â”‚   â”œâ”€â”€ registry/           # parameters.json, assets.json
â”‚   â””â”€â”€ test_data/          # Sample .xlsx files
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ track_a/            # Excel Parser UI (Streamlit)
â”‚   â””â”€â”€ track_b/            # Onboarding Wizard UI (Streamlit)
â””â”€â”€ docker-compose.yml
```

---

# ðŸ” Environment Configuration

Environment variables (Railway or local):

```
GEMINI_API_KEY=your_api_key
GEMINI_MODEL=gemini-1.5-flash
```

Backend listens on dynamic `$PORT` for Railway compatibility.

---

# ðŸ§ª Local Development (Docker)

```bash
# Clone repository
git clone https://github.com/srijanxcode/latspace-ai.git
cd latspace-ai

# Create environment file
cp .env.example .env
# Add your GEMINI_API_KEY inside .env

# Build containers
make build

# Start services
make up

# Generate sample Excel files
make create-test-data
```

### Local URLs

| Service | URL |
|----------|------|
| Backend Docs | http://localhost:8000/docs |
| Track A UI | http://localhost:8501 |
| Track B UI | http://localhost:8502 |

---

# ðŸ’¡ Key Engineering Decisions

- Hybrid AI + deterministic design
- No per-cell LLM calls (cost control)
- Pydantic validation everywhere
- Clean separation of concerns
- Containerized architecture
- Railway-ready deployment configuration

---

# ðŸš€ Production Deployment

- Backend deployed as Railway service
- Track A and Track B deployed as separate Railway services
- Dynamic port binding
- Secure environment variable handling
- Independent scaling per service

---

# ðŸ”® Future Improvements

- Chunked streaming for very large files (>1000 rows)
- Persistent wizard sessions (SQLite / Redis)
- Unit tests for parser & validator
- Caching header mappings
- CI/CD integration
- Usage analytics & monitoring

---

# ðŸ“Œ Summary

LatSpace AI demonstrates:

- Practical LLM integration
- Clean backend architecture
- Full-stack system design
- Cost-efficient AI usage
- Production-ready deployment

This project showcases thoughtful engineering â€” not just API calls.